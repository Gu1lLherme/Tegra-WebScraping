# ü§ñ Tegra Challenger: Web scraping workflow with n8n ü§ñ

## Desafio do Projeto

**Tegra-WebScraping:** Construir um fluxo de trabalho de automa√ß√£o de web scraping usando **n8n** que:  
- Extrai conte√∫do de websites  
- Lida com medidas comuns anti-bot  
- Armazena os dados processados em um banco de dados vetorial **Supabase** para pesquisa sem√¢ntica  
- Utiliza componentes de IA com **OpenAI Model** para gera√ß√£o de embeddings e RAG.

---

## 1. Configura√ß√£o (Setup)

Para executar este workflow, voc√™ precisar√° dos seguintes servi√ßos e credenciais:

| Servi√ßo          | Credencial                       | Necess√°ria | Descri√ß√£o                                                                 |
|------------------|----------------------------------|----------- |----------------------------------------------------------------------------|
| n8n              | N/A                              | ‚úÖ         | Ambiente de execu√ß√£o para o `workflow.json`.                              |
| Google Sheets    | Chave de API / OAuth 2.0         | ‚úÖ         | Fonte de dados inicial para as URLs a serem processadas.                  |
| Supabase         | URL do Projeto + `anon key`      | ‚úÖ         | Banco de dados principal para o Vector Store e tabela de status.          |
| OpenAI           | Chave de API                     | ‚úÖ         | Utilizada para gerar embeddings (vetores num√©ricos).                      |

### Configura√ß√£o passo a passo

1. **Importar o Workflow**  
   - Importe o arquivo `workflow.json` no seu ambiente n8n.

2. **Configurar a Tabela de Input (Google Sheets)**  
   - Crie uma planilha com as colunas m√≠nimas:  
     - `url`  
     - `status`  
   - Inicialize a coluna `status` com `PENDENTE` para as URLs que precisam ser processadas.

3. **Atualizar Credenciais no n8n**  
   - Configure os n√≥s do **Google Sheets**, **Supabase** e **OpenAI** com suas credenciais.

4. **Configurar o N√≥ Supabase (LOAD - Upload to Database)**  
   - Verifique se a tabela no Supabase est√° pronta para receber os dados (campos para `chunk`, `metadata` e `embedding`).

5. **Pronto para Executar **  
   - O workflow pode ser ativado manualmente ou via **cron job**.

---

## 2. Documenta√ß√£o do Workflow (Vis√£o Geral da Arquitetura)

O workflow est√° dividido em **5 etapas l√≥gicas**:

### 1Ô∏è‚É£ Entrada de Informa√ß√µes (Input)
- **Trigger:** O workflow √© iniciado manualmente.  
- **Google Sheets:** Busca as URLs de input.  
- **Verificador de Status:** Filtra apenas URLs com `PENDENTE`.

---

### 2Ô∏è‚É£ EXTRA√á√ÉO (Extract)
Respons√°vel por navegar e extrair o conte√∫do principal das p√°ginas, com mecanismo anti-bot.

- **LOOP PRINCIPAL:** Itera sobre as URLs.  
- **Puppeteer:** Faz a extra√ß√£o inicial (renderiza√ß√£o completa).
- **Mecanismo de Retentativas:** Caso a extra√ß√£o falhe, o Puppeteer tenta novamente at√© **2 vezes** antes de marcar a URL como falha.  
- **Filtro de Links:** Limita a 10 sublinks relevantes por p√°gina.  
- **LOOP SECUND√ÅRIO:** Extrai conte√∫do dos sublinks filtrados.  

---

### 3Ô∏è‚É£ TRANSFORME (Transform)
Prepara o texto para gera√ß√£o de embeddings.

- **Combina Conte√∫dos:** Consolida texto principal + sublinks.  
- **Intelligent Chunking:** Divide o texto em chunks menores e coesos para melhorar a busca sem√¢ntica.

---

### 4Ô∏è‚É£ LOAD (Carregamento)
- **OpenAI Embeddings:** Gera vetores num√©ricos para cada chunk.  
- **Supabase Vector Store:** Insere chunks, embeddings e metadados.  
- **Atualiza Status:** Marca URL como `PROCESSADO` no Google Sheets.

---

### 5Ô∏è‚É£ Busca Sem√¢ntica (RAG Agent Architecture)
Arquitetura que consome os dados extra√≠dos.

- **Metadata Agent & RAG Agent:** Usa LLM (OpenAI) para processar consultas.  
- **Vector Store com Rerank:** Busca sem√¢ntica no Supabase e reclassifica resultados antes de gerar a resposta final.

---

## 3. Perguntas a Abordar
Este projeto visa responder:
- Como automatizar a extra√ß√£o e indexa√ß√£o de conte√∫do web de forma robusta?
- Como lidar com medidas anti-bot em larga escala?
- Como estruturar dados para busca sem√¢ntica eficiente?

---

## 4. Desafio: Parte Mais Dif√≠cil & Solu√ß√£o

**Desafio:**  
Garantir a robustez da extra√ß√£o dos links internos da pagina principal dos websites e aos bloqueios comuns (Cloudflare, CAPTCHAs, tempo de carregamento, etc.).

**Solu√ß√µes adotadas:**

- **Estrat√©gia H√≠brida com Puppeteer:**  
  Utiliza√ß√£o do **Puppeteer** no loop principal para lidar com p√°ginas din√¢micas renderizadas em JavaScript, garantindo maior fidelidade na captura do conte√∫do.

- **Mecanismo de Retentativas:**  
  Em caso de falha na extra√ß√£o, o Puppeteer executa automaticamente **at√© 2 novas tentativas** antes de marcar a URL como n√£o processada.  
  Isso permite contornar falhas tempor√°rias (ex: timeouts, carregamento lento) sem depender de servi√ßos externos.

- **Filtro de Links Inteligente:**  
  Reduz o ru√≠do ao limitar e priorizar sublinks relevantes, otimizando tempo de execu√ß√£o e qualidade do conte√∫do extra√≠do.

---

## 5. Escalabilidade: Processando 500 URLs/dia

Para escalar de forma eficiente:

1. **Scraping Distribu√≠do/Gerenciado:**  
   Migrar do Puppeteer local para uma **API de scraping com proxies rotativos**.

2. **Execu√ß√£o Paralela:**  
   Configurar o n8n em **modo Cluster**, permitindo processamento paralelo no LOOP PRINCIPAL.

3. **Fila de Tarefas:**  
   Substituir Google Sheets por uma **fila (ex: Redis)** ou banco de dados para enfileirar tarefas ass√≠ncronas em larga escala.

---

## 6. Melhoria Futuras

### **Sistema de Qualidade e Classifica√ß√£o Sem√¢ntica Pr√©-Chunking**

Antes do chunking, aplicar um n√≥ LLM para:

- **Limpeza de Ru√≠do:**  
  Remover elementos como rodap√©s, menus e boilerplate.  

- **Classifica√ß√£o de Qualidade:**  
  Avaliar densidade e relev√¢ncia do conte√∫do.  
   Permite descartar p√°ginas vazias ou de baixa qualidade, reduzindo custos de API e garantindo dados de alto valor no Vector Store.

---

## Cr√©ditos
Desafio desenvolvido no contexto Tegra Challenger, utilizando:
- [n8n](https://n8n.io)  
- [Supabase](https://supabase.com)  
- [OpenAI](https://openai.com)  
- [Puppeteer](https://github.com/drudge/n8n-nodes-puppeteer)
